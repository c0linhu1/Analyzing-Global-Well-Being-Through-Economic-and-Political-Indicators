{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0dcdcc62",
   "metadata": {},
   "source": [
    "# Phase II: Data Curation, Exploratory Analysis and Plotting (5\\%)\n",
    "\n",
    "### Team Members:\n",
    "- Colin Hui\n",
    "- Derek Aslan\n",
    "- Aydan Ali\n",
    "- Conor Cummings\n",
    "\n",
    "\n",
    "## Part 1: \n",
    "(1%) Expresses the central motivation of the project and explains the (at least) two key questions to be explored. Gives a summary of the data processing pipeline so a technical expert can easily follow along."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05a6bfb5",
   "metadata": {},
   "source": [
    "## Problem Motivation \n",
    "\n",
    "Global economic development remains uneven, especially in today's world where countries  are experiencing different levels of population wellbeing despite similar geopolitical circumstances. Understanding the relationships between economic indicators, political factors, and policy decisions is important for identifying pathways to improved quality of life. This analysis would focus on how these indicators and factors influence population wellbeing across different world regions/countries, overall providing insights that could inform evidence-based policy decisions for sustainable development.\n",
    "The key questions are as follows:\n",
    "\n",
    "1. Are there peaks in bike usage during certain times of the day?\n",
    "2. Which stations have the highest traffic, and how does the distribution of bike usage vary geographically? Can we identify high-demand areas that would benefit from more bikes?\n",
    "3. How does bike trip duration vary by user type (eg. age, gender, membership status)?\n",
    "4. Can we predict the trip duration based on factors such as the time of day, user demographics, and starting/ending stations?\n",
    "\n",
    "Motivating sources:\n",
    "- Northeastern University. \"Améera.\" Northeastern University Landscapes, Northeastern University, https://landscapes.northeastern.edu/ameera/. Accessed 30 Sept. 2024.\n",
    "- \"Environmental Awareness Month: Go Green with Blue Cross and Bluebikes in September.\" Blue Bikes Boston, http://blog.bluebikes.com/blog/environmental-awareness-month-go-green-with-blue-cross-and-bluebikes-in-september. Accessed 30 Sept. 2024.\n",
    "- Streets Cabinet. \"Streets Cabinet Announces Bluebikes Expansion Planning.\" Boston.gov, 12 Aug. 2024, https://www.boston.gov/news/streets-cabinet-announces-bluebikes-expansion-planning. Accessed 30 Sept. 2024."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3492a06",
   "metadata": {},
   "source": [
    "## Summary of the Data Processing Pipeline\n",
    "\n",
    "1. Web scrape to get the raw data\n",
    "2. Clean the data to prepare the data frame for visualization and analysis\n",
    "3. Visualize using plotting libraries, such as Seaborn, Plotly, and Matplotlib\n",
    "\n",
    "To process the data, we will first acquire the Bluebikes datasets. This involves web scraping to successfully collect the data, cleaning the data, and then saving the datasets as (cleaned) .csv files and importing them into our Jupyter Notebook. The cleaning process consists of removing any invalid values, including NaN, n/a, and 0 when applicable. This step will also involve handling missing or inconsistent values across columns such as start station ID, end station ID, and bikeId, converting the starttime and stoptime columns to DateTime format, and removing unanalyzable records like trips with negative tripduration. Next, we will address our key questions. This includes extracting the hour and day of the week from the start time and calculating the user’s age from their birth year to help us analyze usage patterns more effectively. Seeing that there is data in several files, we will combine them using common identifiers like the start station ID and end station ID. After that, we will perform more data analysis to create basic statistics and visualizations. This will include time series plots showing peaks in bike usage and geographical heatmaps (using imported libraries Seaborn, Matplotlib, and Plotly) displaying station traffic based on the names of the start and end stations. These steps will help us address key questions related to peak usage times, station demand, and trip duration patterns across different user demographics. Finally, the cleaned data will be prepared for machine learning by selecting relevant features for predictive modeling of blue bike trip duration."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68682951",
   "metadata": {},
   "source": [
    "## Part 2: \n",
    "(2\\%) Obtains, cleans, and merges all data sources involved in the project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cc0813e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               region          incomeLevel\n",
      "AW                         Latin America & Caribbean           High income\n",
      "AF  Middle East, North Africa, Afghanistan & Pakistan           Low income\n",
      "AO                                Sub-Saharan Africa   Lower middle income\n",
      "AL                              Europe & Central Asia  Upper middle income\n",
      "AD                              Europe & Central Asia          High income\n",
      "..                                                ...                  ...\n",
      "XK                              Europe & Central Asia  Upper middle income\n",
      "YE  Middle East, North Africa, Afghanistan & Pakistan           Low income\n",
      "ZA                                Sub-Saharan Africa   Upper middle income\n",
      "ZM                                Sub-Saharan Africa   Lower middle income\n",
      "ZW                                Sub-Saharan Africa   Lower middle income\n",
      "\n",
      "[217 rows x 2 columns]\n",
      "    SP.POP.TOTL  NY.GNP.PCAP.CD  SI.POV.DDAY  SI.POV.GINI  MS.MIL.XPND.GD.ZS  \\\n",
      "ZH  750503764.0     1549.411972          NaN          NaN           1.036544   \n",
      "ZI  509398589.0     1697.190709          NaN          NaN           1.198884   \n",
      "XC  350292725.0    44564.667193          NaN          NaN           1.610692   \n",
      "EU  449425965.0    40801.652703          NaN          NaN           1.716629   \n",
      "XE  917304254.0     1102.212723          NaN          NaN           1.388821   \n",
      "..          ...             ...          ...          ...                ...   \n",
      "VI     104917.0             NaN          NaN          NaN                NaN   \n",
      "PS    5165775.0     4310.000000          2.1         36.4                NaN   \n",
      "YE   39390799.0             NaN          NaN          NaN                NaN   \n",
      "ZM   20723965.0     1290.000000          NaN          NaN           1.303002   \n",
      "ZW   16340822.0     2060.000000          NaN          NaN           0.248808   \n",
      "\n",
      "      VA.EST  \n",
      "ZH       NaN  \n",
      "ZI       NaN  \n",
      "XC       NaN  \n",
      "EU       NaN  \n",
      "XE       NaN  \n",
      "..       ...  \n",
      "VI       NaN  \n",
      "PS -1.118067  \n",
      "YE -1.550217  \n",
      "ZM -0.047946  \n",
      "ZW -1.092633  \n",
      "\n",
      "[243 rows x 6 columns]\n",
      "    SP.POP.TOTL  NY.GNP.PCAP.CD  SI.POV.DDAY  SI.POV.GINI  MS.MIL.XPND.GD.ZS  \\\n",
      "AW     107359.0         30120.0          NaN          NaN                NaN   \n",
      "AF   41454761.0           370.0          NaN          NaN                NaN   \n",
      "AO   36749906.0          2130.0          NaN          NaN           1.332529   \n",
      "AL    2745972.0          7680.0          NaN          NaN           1.743992   \n",
      "AD      80856.0         47920.0          NaN          NaN                NaN   \n",
      "..          ...             ...          ...          ...                ...   \n",
      "XK    1682668.0          6290.0          NaN          NaN           1.254180   \n",
      "YE   39390799.0             NaN          NaN          NaN                NaN   \n",
      "ZA   63212384.0          6480.0          NaN          NaN           0.733137   \n",
      "ZM   20723965.0          1290.0          NaN          NaN           1.303002   \n",
      "ZW   16340822.0          2060.0          NaN          NaN           0.248808   \n",
      "\n",
      "      VA.EST                                             region  \\\n",
      "AW  1.019175                         Latin America & Caribbean    \n",
      "AF -1.852901  Middle East, North Africa, Afghanistan & Pakistan   \n",
      "AO -0.737252                                Sub-Saharan Africa    \n",
      "AL  0.168997                              Europe & Central Asia   \n",
      "AD  0.996940                              Europe & Central Asia   \n",
      "..       ...                                                ...   \n",
      "XK -0.088809                              Europe & Central Asia   \n",
      "YE -1.550217  Middle East, North Africa, Afghanistan & Pakistan   \n",
      "ZA  0.744892                                Sub-Saharan Africa    \n",
      "ZM -0.047946                                Sub-Saharan Africa    \n",
      "ZW -1.092633                                Sub-Saharan Africa    \n",
      "\n",
      "            incomeLevel  \n",
      "AW          High income  \n",
      "AF           Low income  \n",
      "AO  Lower middle income  \n",
      "AL  Upper middle income  \n",
      "AD          High income  \n",
      "..                  ...  \n",
      "XK  Upper middle income  \n",
      "YE           Low income  \n",
      "ZA  Upper middle income  \n",
      "ZM  Lower middle income  \n",
      "ZW  Lower middle income  \n",
      "\n",
      "[217 rows x 8 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import json\n",
    "\n",
    "\n",
    "\n",
    "indicators = {\n",
    "    'SP.POP.TOTL': 'Population, total',\n",
    "    'NY.GNP.PCAP.CD': 'GDP Per Captia',\n",
    "    'SI.POV.DDAY': 'Poverty headcount ratio at $3.00 a day (2021 PPP)',\n",
    "    'SI.POV.GINI': 'Gini index',\n",
    "    'MS.MIL.XPND.GD.ZS': 'Military expenditure (% of GDP)',\n",
    "    'VA.EST': 'Voice and Accountability: Estimate'\n",
    "}\n",
    "\n",
    "params = {\n",
    "    'format': 'json',\n",
    "    'per_page': '300', # This makes sure all countries are returned\n",
    "    'date': '2023' #Query just one year\n",
    "}\n",
    "\n",
    "\n",
    "def get_api_url(indicator, params):\n",
    "    \"\"\"\n",
    "    Constructs a URL for the API call, to query a given indicator and with a given set of parameters.\n",
    "\n",
    "    Args:\n",
    "        indicator: the indicator ID string\n",
    "        params: a dictionary containing the API call parameters\n",
    "\n",
    "    Returns:\n",
    "        A URL to send an HTTP request to to get the API data\n",
    "    \"\"\"\n",
    "    baseurl = 'https://api.worldbank.org/v2/country/all/indicator/'\n",
    "\n",
    "    url = baseurl + indicator + '?'\n",
    "    for param in params.keys():\n",
    "        url = url + param + '=' + params[param] + '&'\n",
    "    return url\n",
    "\n",
    "\"\"\"\n",
    "You said you want the region only - are you thinking that were gonna group the countries by region and \n",
    "use one of the indicators and then get like the mean of that indicator for each region and then do like a \n",
    "grouped bar plot\n",
    "- if so then after we merge, ill groupby region \n",
    "\n",
    "\"\"\"\n",
    "def get_country_data():\n",
    "    \"\"\"\n",
    "    Gets country region and income level as a dataframe indexed by country id.\n",
    "\n",
    "    Args: \n",
    "        None\n",
    "\n",
    "    Returns:\n",
    "        DataFrame with country id as index and region/incomeLevel as columns\n",
    "\n",
    "    \"\"\"\n",
    "    response = requests.get(\"https://api.worldbank.org/v2/country?format=json&per_page=296\")\n",
    "    country_data = json.loads(response.text)[1]\n",
    "\n",
    "    country_dct = {}\n",
    "\n",
    "    for dict in country_data:\n",
    "        if dict[\"region\"][\"value\"] != \"Aggregates\":\n",
    "            country_dct[dict[\"iso2Code\"]] = {\n",
    "                \"region\": dict[\"region\"][\"value\"],\n",
    "                \"incomeLevel\": dict[\"incomeLevel\"][\"value\"],\n",
    "            }\n",
    "    df = pd.DataFrame.from_dict(country_dct, orient = \"index\")\n",
    "                \n",
    "    print(df)\n",
    "\n",
    "    return df\n",
    "\n",
    "def get_indicator_data(indicators):\n",
    "    \"\"\"\n",
    "    Gets and cleans the indicator data into a dataframe indexed by country id.\n",
    "\n",
    "    Args:\n",
    "        indicator: the indicator ID string\n",
    "\n",
    "    Returns:\n",
    "        Dataframe with country id as index and the indicators as columns\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    indicator_data = {}\n",
    "    #Loop through each indicator and make an API call for each. Unfortunately, each API call can only return data for 1 indicator.\n",
    "    for indicator in indicators.keys():\n",
    "        indicator_data[indicator] = json.loads(requests.get(get_api_url(indicator, params)).text)\n",
    "\n",
    "    indicator_series_list = []\n",
    "\n",
    "    for indicator in indicator_data.keys():\n",
    "        indicator_dict = {}\n",
    "        for country in indicator_data[indicator][1]:\n",
    "            country_id = country['country']['id']\n",
    "            if len(country_id) == 2 and country_id.isalpha() and country_id.isupper():\n",
    "                indicator_dict[country_id] = country['value']\n",
    "\n",
    "        indicator_series = pd.Series(indicator_dict)\n",
    "        indicator_series.name = indicator\n",
    "        indicator_series_list.append(indicator_series)\n",
    "    output = pd.DataFrame(indicator_series_list).transpose()\n",
    "    print(output)\n",
    "    return output\n",
    "\n",
    "\n",
    "def merge_data(country_df, indicator_df):\n",
    "    \"\"\"\n",
    "    Merges country dataframe with indicator dataframe based on the country id index.\n",
    "    \n",
    "    Args:\n",
    "        country_df: DataFrame with region/income data\n",
    "        indicator_df: DataFrame with indicator data\n",
    "        \n",
    "    Returns:\n",
    "        finalized merged dataframe containing country and indicator data\n",
    "    \"\"\"\n",
    "    merge_df = pd.merge(indicator_df, country_df, left_index = True,\n",
    "                         right_index = True, how = \"right\")\n",
    "    return merge_df\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    country_df = get_country_data()\n",
    "    indicator_df = get_indicator_data(indicators)\n",
    "    merged_data = merge_data(country_df, indicator_df)\n",
    "    print(merged_data)\n",
    "\n",
    "    merged_data.to_csv('world_bank_data_2023.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71a36fd1",
   "metadata": {},
   "source": [
    "## Part 3:\n",
    "(2\\%) Builds at least two visualizations (graphs/plots) from the data which help to understand or answer the questions of interest. These visualizations will be graded based on how much information they can effectively communicate to readers. Please make sure your visualization are sufficiently distinct from each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e53d0d23",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ds",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
